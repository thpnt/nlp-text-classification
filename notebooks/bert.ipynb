{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "project_root = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gcp import load_data_from_gcs\n",
    "from google.auth import credentials\n",
    "from google.cloud import storag\n",
    "service_account = os.path.join(project_root, os.getenv(\"GCP_SERVICE_ACCOUNT\"))\n",
    "client = storage.Client.from_service_account_json(service_account)\n",
    "\n",
    "# Load data from GCS\n",
    "bucket_name = os.getenv(\"GCP_BUCKET_NAME\")\n",
    "file_name = os.getenv(\"GCP_DATA_PATH\")\n",
    "data = load_data_from_gcs(bucket_name, file_name, client)\n",
    "\n",
    "data[\"tokens\"] = data[\"tokens\"].apply(lambda x: eval(x))\n",
    "data[\"label\"] = data[\"label\"].astype(int)\n",
    "# Shuffle data and reset_index\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>Crying to the G20 that some Americans don't li...</td>\n",
       "      <td>1</td>\n",
       "      <td>fef26687bd954e0ba7f7b4448aabfaab</td>\n",
       "      <td>crying to the g that some americans do not lik...</td>\n",
       "      <td>[cry, to, the, g, that, some, american, do, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>RT @xDSmooth: I took yo job bitch @1BookieG</td>\n",
       "      <td>1</td>\n",
       "      <td>e35367e0277343fa8f60cbef166dbc0e</td>\n",
       "      <td>i took hello job bitch person</td>\n",
       "      <td>[i, take, hello, job, bitch, person]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toxic_comment</td>\n",
       "      <td>\"\\n\\n Go fuck yourself!! \\n\\n  fuck you   \"</td>\n",
       "      <td>2</td>\n",
       "      <td>c1c176d2b62246fda473d0280629fab6</td>\n",
       "      <td>go fuck yourself fuck you</td>\n",
       "      <td>[go, fuck, yourself, fuck, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toxic_comment</td>\n",
       "      <td>I fix articles on notable subjects frequently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15b181935a9e4ba3aeb46afe58dec582</td>\n",
       "      <td>i fix articles on notable subjects frequently ...</td>\n",
       "      <td>[i, fix, article, on, notable, subject, freque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toxic_comment</td>\n",
       "      <td>FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHE...</td>\n",
       "      <td>2</td>\n",
       "      <td>046ec2535ad246bdb11d0671fbcf6ecf</td>\n",
       "      <td>fuck atheist count fuck atheist count fuck ath...</td>\n",
       "      <td>[fuck, atheist, count, fuck, atheist, count, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source                                               text  label  \\\n",
       "0    hate_speech  Crying to the G20 that some Americans don't li...      1   \n",
       "1    hate_speech        RT @xDSmooth: I took yo job bitch @1BookieG      1   \n",
       "2  toxic_comment        \"\\n\\n Go fuck yourself!! \\n\\n  fuck you   \"      2   \n",
       "3  toxic_comment  I fix articles on notable subjects frequently ...      0   \n",
       "4  toxic_comment  FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHE...      2   \n",
       "\n",
       "                                 id  \\\n",
       "0  fef26687bd954e0ba7f7b4448aabfaab   \n",
       "1  e35367e0277343fa8f60cbef166dbc0e   \n",
       "2  c1c176d2b62246fda473d0280629fab6   \n",
       "3  15b181935a9e4ba3aeb46afe58dec582   \n",
       "4  046ec2535ad246bdb11d0671fbcf6ecf   \n",
       "\n",
       "                                      corrected_text  \\\n",
       "0  crying to the g that some americans do not lik...   \n",
       "1                      i took hello job bitch person   \n",
       "2                          go fuck yourself fuck you   \n",
       "3  i fix articles on notable subjects frequently ...   \n",
       "4  fuck atheist count fuck atheist count fuck ath...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [cry, to, the, g, that, some, american, do, no...  \n",
       "1               [i, take, hello, job, bitch, person]  \n",
       "2                    [go, fuck, yourself, fuck, you]  \n",
       "3  [i, fix, article, on, notable, subject, freque...  \n",
       "4  [fuck, atheist, count, fuck, atheist, count, f...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_length</th>\n",
       "      <th>unique_tokens</th>\n",
       "      <th>log_tokens_length</th>\n",
       "      <th>unique_ratio</th>\n",
       "      <th>log_unique_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic_comment</td>\n",
       "      <td>\"I defy you ==\\nTo find anything that shows I'...</td>\n",
       "      <td>0</td>\n",
       "      <td>fca5d312945c4365a4768bbbcb2d8d9f</td>\n",
       "      <td>i defy you</td>\n",
       "      <td>[i, defy, you]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toxic_comment</td>\n",
       "      <td>What a lovely surprise! \\n\\n ]]\\nHello Phaedri...</td>\n",
       "      <td>0</td>\n",
       "      <td>9d6d04e4216a4bd98b040dd98ead6656</td>\n",
       "      <td>what a lovely surprise hello phaedriel it cert...</td>\n",
       "      <td>[what, a, lovely, surprise, hello, &lt;UNK&gt;, it, ...</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.735849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toxic_comment</td>\n",
       "      <td>I still think you are a tit.</td>\n",
       "      <td>1</td>\n",
       "      <td>111c766778f443bf88582087c7f5f2e3</td>\n",
       "      <td>i still think you are a tit</td>\n",
       "      <td>[i, still, think, you, be, a, tit]</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toxic_comment</td>\n",
       "      <td>\"== 8 Focused vs. 8 Flexible (8B) ==\\n\\nI adde...</td>\n",
       "      <td>0</td>\n",
       "      <td>f449ff0dfff14526bebac6360ce205c0</td>\n",
       "      <td>i added a situation needed to the assertion th...</td>\n",
       "      <td>[i, add, a, situation, need, to, the, assertio...</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toxic_comment</td>\n",
       "      <td>I'm gonna revert because I found all that info...</td>\n",
       "      <td>0</td>\n",
       "      <td>b841045744b646af9298d16f44684eb6</td>\n",
       "      <td>i am going to revert because i found all that ...</td>\n",
       "      <td>[i, be, go, to, revert, because, i, find, all,...</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source                                               text  label  \\\n",
       "0  toxic_comment  \"I defy you ==\\nTo find anything that shows I'...      0   \n",
       "1  toxic_comment  What a lovely surprise! \\n\\n ]]\\nHello Phaedri...      0   \n",
       "2  toxic_comment                       I still think you are a tit.      1   \n",
       "3  toxic_comment  \"== 8 Focused vs. 8 Flexible (8B) ==\\n\\nI adde...      0   \n",
       "4  toxic_comment  I'm gonna revert because I found all that info...      0   \n",
       "\n",
       "                                 id  \\\n",
       "0  fca5d312945c4365a4768bbbcb2d8d9f   \n",
       "1  9d6d04e4216a4bd98b040dd98ead6656   \n",
       "2  111c766778f443bf88582087c7f5f2e3   \n",
       "3  f449ff0dfff14526bebac6360ce205c0   \n",
       "4  b841045744b646af9298d16f44684eb6   \n",
       "\n",
       "                                      corrected_text  \\\n",
       "0                                         i defy you   \n",
       "1  what a lovely surprise hello phaedriel it cert...   \n",
       "2                        i still think you are a tit   \n",
       "3  i added a situation needed to the assertion th...   \n",
       "4  i am going to revert because i found all that ...   \n",
       "\n",
       "                                              tokens  tokens_length  \\\n",
       "0                                     [i, defy, you]              3   \n",
       "1  [what, a, lovely, surprise, hello, <UNK>, it, ...             53   \n",
       "2                 [i, still, think, you, be, a, tit]              7   \n",
       "3  [i, add, a, situation, need, to, the, assertio...             59   \n",
       "4  [i, be, go, to, revert, because, i, find, all,...             44   \n",
       "\n",
       "   unique_tokens  log_tokens_length  unique_ratio  log_unique_ratio  \n",
       "0              3           1.386294      1.000000          1.000000  \n",
       "1             39           3.988984      0.735849          0.735849  \n",
       "2              7           2.079442      1.000000          1.000000  \n",
       "3             44           4.094345      0.745763          0.745763  \n",
       "4             37           3.806662      0.840909          0.840909  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from pickle\n",
    "path = os.path.join(project_root, \"datasets/processed/data.pkl\")\n",
    "data = pd.read_pickle(path)\n",
    "data['label'] = data['label'].apply(lambda x: 1 if x == 2 else x)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 18:27:50.926938: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-12-02 18:27:50.927014: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-12-02 18:27:50.927033: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-12-02 18:27:50.927308: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-02 18:27:50.927805: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from utils.custom_metrics import RecallMulticlass, PrecisionMulticlass, F1ScoreMulticlass, WeightedCategoricalCrossEntropy\n",
    "\n",
    "# metrics\n",
    "metrics = [RecallMulticlass(name=\"recall\", n_class=2), PrecisionMulticlass(name=\"precision\", n_class=2), F1ScoreMulticlass(name=\"f1\", n_class=2)]\n",
    "\n",
    "# weights\n",
    "weights = data[\"label\"].value_counts(normalize=True).sort_index().values\n",
    "weights = 1/weights\n",
    "weights = weights/weights.sum()\n",
    "\n",
    "# loss\n",
    "loss = WeightedCategoricalCrossEntropy(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105402,) (11712,) (105402, 2) (11712, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "X, y = data[\"corrected_text\"], data[\"label\"]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# Tokenize\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode the data\n",
    "def encode_data(texts, max_length=128):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "\n",
    "# Encode the training data\n",
    "encoded_data = encode_data(X_train)\n",
    "encoded_val_data = encode_data(X_test)\n",
    "\n",
    "# Convert labels to tensor\n",
    "labels = tf.convert_to_tensor(y_train)\n",
    "val_labels = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train class distribution: [0.6660215  0.33397847]\n",
      "y_test class distribution: [0.66282445 0.33717555]\n"
     ]
    }
   ],
   "source": [
    "# Investigate class distribution in y_train and y_test\n",
    "\n",
    "print(f\"y_train class distribution: {tf.divide(tf.reduce_sum(labels, axis=0), tf.reduce_sum(labels))}\")\n",
    "print(f\"y_test class distribution: {tf.divide(tf.reduce_sum(val_labels, axis=0), tf.reduce_sum(val_labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(encoded_data),\n",
    "    labels\n",
    "))\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(encoded_val_data),\n",
    "    val_labels\n",
    "))\n",
    "\n",
    "# Batch the dataset\n",
    "batch_size = 128\n",
    "training_dataset = training_dataset.batch(batch_size)\n",
    "validation_dataset = validation_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Early stopping\n",
    "\n",
    "def early_stopping():\n",
    "    return tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_recall',     \n",
    "        patience=10,             \n",
    "        mode='max',            \n",
    "        min_delta=0.001,        \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "# TensorBoard\n",
    "#def tensorboard(log_dir:str = os.path.join(project_root, \"logs\", \"fit\")):\n",
    "#    return tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# ModelCheckpoint\n",
    "def model_checkpoint(model_name):\n",
    "    return tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(project_root, \"models\", \"bert\", f\"{model_name}\"),\n",
    "        monitor='val_recall',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        save_format='tf',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stopping(), model_checkpoint(\"bert_model_test\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 128)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_bert_model_4 (TFBertMod  TFBaseModelOutputWithPooli   1094822   ['input_ids[0][0]',           \n",
      " el)                         ngAndCrossAttentions(last_   40         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 128, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 128)                  98432     ['tf_bert_model_4[0][1]']     \n",
      "                                                                                                  \n",
      " dropout_189 (Dropout)       (None, 128)                  0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 64)                   8256      ['dropout_189[0][0]']         \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 2)                    130       ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109589058 (418.05 MB)\n",
      "Trainable params: 106818 (417.26 KB)\n",
      "Non-trainable params: 109482240 (417.64 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel, BertTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def build_bert_model(loss: list, metrics: list, name:str = \"bert_model\"):\n",
    "    # Load the pre-trained BERT model\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Freeze the BERT model layers\n",
    "    for layer in bert_model.layers:  # Freeze all layers\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Define the input layers\n",
    "    input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "    # Get the output from the BERT model\n",
    "    bert_outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Use the pooled output for classification\n",
    "    pooled_output = bert_outputs.pooler_output\n",
    "\n",
    "    # Add custom layers\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(pooled_output)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output, name=name)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "\n",
    "    # Summary of the model\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_bert_model(loss, metrics, \"bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theopinto--dalle/code/arewetoxic/env/lib/python3.10/site-packages/keras/src/engine/functional.py:642: UserWarning: Input dict contained keys ['token_type_ids'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "2024-12-02 18:36:51.023782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824/824 [==============================] - ETA: 0s - loss: 0.1879 - recall: 0.8109 - precision: 0.7881 - f1: 0.7994\n",
      "Epoch 1: val_recall improved from -inf to 0.86064, saving model to /Users/theopinto--dalle/code/arewetoxic/models/bert/bert_model_test\n",
      "824/824 [==============================] - 3062s 4s/step - loss: 0.1879 - recall: 0.8109 - precision: 0.7881 - f1: 0.7994 - val_loss: 0.1470 - val_recall: 0.8606 - val_precision: 0.8705 - val_f1: 0.8655\n",
      "Epoch 2/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.1722 - recall: 0.8344 - precision: 0.8122 - f1: 0.8232\n",
      "Epoch 2: val_recall improved from 0.86064 to 0.87561, saving model to /Users/theopinto--dalle/code/arewetoxic/models/bert/bert_model_test\n",
      "824/824 [==============================] - 2939s 4s/step - loss: 0.1722 - recall: 0.8344 - precision: 0.8122 - f1: 0.8232 - val_loss: 0.1352 - val_recall: 0.8756 - val_precision: 0.8498 - val_f1: 0.8625\n",
      "Epoch 3/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.1761 - recall: 0.8326 - precision: 0.8107 - f1: 0.8215\n",
      "Epoch 3: val_recall did not improve from 0.87561\n",
      "824/824 [==============================] - 2972s 4s/step - loss: 0.1761 - recall: 0.8326 - precision: 0.8107 - f1: 0.8215 - val_loss: 0.1350 - val_recall: 0.8752 - val_precision: 0.8544 - val_f1: 0.8647\n",
      "Epoch 4/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.1779 - recall: 0.8328 - precision: 0.8112 - f1: 0.8219\n",
      "Epoch 4: val_recall improved from 0.87561 to 0.87909, saving model to /Users/theopinto--dalle/code/arewetoxic/models/bert/bert_model_test\n",
      "824/824 [==============================] - 2883s 3s/step - loss: 0.1779 - recall: 0.8328 - precision: 0.8112 - f1: 0.8219 - val_loss: 0.1318 - val_recall: 0.8791 - val_precision: 0.8619 - val_f1: 0.8704\n",
      "Epoch 5/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.1859 - recall: 0.8301 - precision: 0.8081 - f1: 0.8189\n",
      "Epoch 5: val_recall improved from 0.87909 to 0.87933, saving model to /Users/theopinto--dalle/code/arewetoxic/models/bert/bert_model_test\n",
      "824/824 [==============================] - 2889s 4s/step - loss: 0.1859 - recall: 0.8301 - precision: 0.8081 - f1: 0.8189 - val_loss: 0.1323 - val_recall: 0.8793 - val_precision: 0.8590 - val_f1: 0.8690\n",
      "Epoch 6/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.1907 - recall: 0.8285 - precision: 0.8067 - f1: 0.8175\n",
      "Epoch 6: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 2913s 4s/step - loss: 0.1907 - recall: 0.8285 - precision: 0.8067 - f1: 0.8175 - val_loss: 0.1706 - val_recall: 0.8457 - val_precision: 0.8786 - val_f1: 0.8618\n",
      "Epoch 7/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.1999 - recall: 0.8260 - precision: 0.8039 - f1: 0.8148\n",
      "Epoch 7: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 3079s 4s/step - loss: 0.1999 - recall: 0.8260 - precision: 0.8039 - f1: 0.8148 - val_loss: 0.2121 - val_recall: 0.8208 - val_precision: 0.8778 - val_f1: 0.8484\n",
      "Epoch 8/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.2129 - recall: 0.8220 - precision: 0.7999 - f1: 0.8108\n",
      "Epoch 8: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 2879s 3s/step - loss: 0.2129 - recall: 0.8220 - precision: 0.7999 - f1: 0.8108 - val_loss: 0.2068 - val_recall: 0.8259 - val_precision: 0.8765 - val_f1: 0.8504\n",
      "Epoch 9/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.2148 - recall: 0.8207 - precision: 0.7987 - f1: 0.8095\n",
      "Epoch 9: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 2834s 3s/step - loss: 0.2148 - recall: 0.8207 - precision: 0.7987 - f1: 0.8095 - val_loss: 0.2174 - val_recall: 0.8208 - val_precision: 0.8688 - val_f1: 0.8441\n",
      "Epoch 10/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.2349 - recall: 0.8154 - precision: 0.7930 - f1: 0.8040\n",
      "Epoch 10: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 2793s 3s/step - loss: 0.2349 - recall: 0.8154 - precision: 0.7930 - f1: 0.8040 - val_loss: 0.3246 - val_recall: 0.7728 - val_precision: 0.8526 - val_f1: 0.8107\n",
      "Epoch 11/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.2622 - recall: 0.8104 - precision: 0.7881 - f1: 0.7991\n",
      "Epoch 11: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 2803s 3s/step - loss: 0.2622 - recall: 0.8104 - precision: 0.7881 - f1: 0.7991 - val_loss: 0.2243 - val_recall: 0.8318 - val_precision: 0.8813 - val_f1: 0.8559\n",
      "Epoch 12/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.2548 - recall: 0.8131 - precision: 0.7909 - f1: 0.8018\n",
      "Epoch 12: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 2793s 3s/step - loss: 0.2548 - recall: 0.8131 - precision: 0.7909 - f1: 0.8018 - val_loss: 0.3488 - val_recall: 0.7704 - val_precision: 0.8518 - val_f1: 0.8091\n",
      "Epoch 13/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.2721 - recall: 0.8086 - precision: 0.7861 - f1: 0.7972\n",
      "Epoch 13: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 2794s 3s/step - loss: 0.2721 - recall: 0.8086 - precision: 0.7861 - f1: 0.7972 - val_loss: 0.4931 - val_recall: 0.7423 - val_precision: 0.8431 - val_f1: 0.7895\n",
      "Epoch 14/100\n",
      "824/824 [==============================] - ETA: 0s - loss: 0.2578 - recall: 0.8118 - precision: 0.7895 - f1: 0.8005\n",
      "Epoch 14: val_recall did not improve from 0.87933\n",
      "824/824 [==============================] - 2801s 3s/step - loss: 0.2578 - recall: 0.8118 - precision: 0.7895 - f1: 0.8005 - val_loss: 0.4624 - val_recall: 0.7444 - val_precision: 0.8473 - val_f1: 0.7925\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(training_dataset, epochs=100, callbacks=callbacks, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x38902b6d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try loading the model by importing weights into empty model\n",
    "# Create a new model\n",
    "# Load the pre-trained BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze the BERT model layers\n",
    "for layer in bert_model.layers:  # Freeze all layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the input layers\n",
    "input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "# Get the output from the BERT model\n",
    "bert_outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Use the pooled output for classification\n",
    "pooled_output = bert_outputs.pooler_output\n",
    "\n",
    "# Add custom layers\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pooled_output)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "test_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "test_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "# Load the weights\n",
    "test_model.load_weights(os.path.join(project_root, \"models\", \"bert_model_test\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
